{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgSxP4WUAGPnqZEy6yidRY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andres931720/Deberes/blob/main/TAREA_ANDRES_VINUEZA%2007%20MIAR%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TAREA ARTÍCULO CIENTÍFICO\n",
        "\n",
        "Andrés Vinueza\n",
        "\n",
        "## 1. Introducción\n",
        "\n",
        "En esta práctica se analiza una arquitectura de red neuronal convolucional 1D (CNN 1D) propuesta en el artículo End-to-End Environmental Sound Classification using a 1D Convolutional Neural Network.\n",
        "El objetivo principal es estudiar una implementación entrenada real, observar la estructura del modelo, analizar el tipo de entrada que recibe y examinar los logits de salida producidos por la red.\n",
        "\n",
        "Para ello, se utiliza el repositorio oficial de los autores, donde se encuentra el archivo 1DCNN.py, el cual implementa la arquitectura descrita en el artículo. El trabajo se centra en el análisis del modelo y no en volver a entrenarlo desde cero."
      ],
      "metadata": {
        "id": "LbfpRD5s1Fb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Implementación utilizada\n",
        "\n",
        "La implementación empleada corresponde al archivo 1DCNN.py del repositorio oficial del artículo.\n",
        "En este archivo, el modelo se construye mediante la función model_generator(), que define completamente la arquitectura de la CNN 1D.\n",
        "\n",
        "Debido a que el código original fue desarrollado para versiones antiguas de Keras, fue necesario realizar ajustes mínimos de compatibilidad, como:\n",
        "\n",
        "completar algunos imports faltantes,\n",
        "\n",
        "actualizar la definición de la función de pérdida,\n",
        "\n",
        "adaptar el optimizador a la API actual de Keras.\n",
        "\n",
        "Estos cambios no modifican la arquitectura ni el funcionamiento del modelo, únicamente permiten que la implementación original se ejecute correctamente en versiones modernas de TensorFlow/Keras."
      ],
      "metadata": {
        "id": "jASZZwAT5Ibr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XRdFe4wb7NL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sajabdoli/End-to-end.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvmLDCWZb97S",
        "outputId": "f00bfc46-c5ab-481e-d303-ffb49f59fa76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'End-to-end'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 46 (delta 12), reused 0 (delta 0), pack-reused 20 (from 1)\u001b[K\n",
            "Receiving objects: 100% (46/46), 266.01 KiB | 2.06 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '1i\\\n",
        "from keras.layers import Conv1D, MaxPool1D, BatchNormalization\\n\\\n",
        "from keras.layers import Flatten, Dropout\\n\\\n",
        "from keras import regularizers, optimizers\\n\\\n",
        "from keras import backend as K\\n\\\n",
        "from functools import partial as wrapped_partial\\n' /content/End-to-end/1DCNN.py\n"
      ],
      "metadata": {
        "id": "3mKuywKNb_tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,30p' /content/End-to-end/1DCNN.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZea7Nb_c8CG",
        "outputId": "f24db9ba-1bbc-4066-87f9-3c495d145962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from keras.layers import Conv1D, MaxPool1D, BatchNormalization\n",
            " from keras.layers import Flatten, Dropout\n",
            " from keras import regularizers, optimizers\n",
            " from keras import backend as K\n",
            " from functools import partial as wrapped_partial\n",
            "\n",
            "from keras.layers import Conv1D, MaxPool1D, BatchNormalization\n",
            " from keras.layers import Flatten, Dropout\n",
            " from keras import regularizers, optimizers\n",
            " from keras import backend as K\n",
            " from functools import partial as wrapped_partial\n",
            "\n",
            "def model_generator():\n",
            "    from keras.layers import Input, Dense\n",
            "    from keras.models import Model\n",
            "    from keras.callbacks import ModelCheckpoint\n",
            "\n",
            "    inp = Input(shape=(50999, 1))\n",
            "\n",
            "    # ----------------------\n",
            "    conv1 = Conv1D(filters=16, kernel_size=64, strides=2, activation='relu', padding='valid')(inp)\n",
            "    norm1 = BatchNormalization()(conv1)\n",
            "    pool1 = MaxPool1D(pool_size=8, strides=8)(norm1)\n",
            "    # ----------------------\n",
            "\n",
            "    conv2 = Conv1D(filters=32, kernel_size=32, strides=2, activation='relu', padding='valid')(pool1)\n",
            "    norm2 = BatchNormalization()(conv2)\n",
            "    pool2 = MaxPool1D(pool_size=8, strides=8)(norm2)\n",
            "\n",
            "    # ----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '1,10d' /content/End-to-end/1DCNN.py\n"
      ],
      "metadata": {
        "id": "dxjLPsDFdFGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '1i from keras.layers import Conv1D, MaxPool1D, BatchNormalization\\nfrom keras.layers import Flatten, Dropout\\nfrom keras import regularizers, optimizers\\nfrom keras import backend as K\\nfrom functools import partial as wrapped_partial\\n' /content/End-to-end/1DCNN.py\n"
      ],
      "metadata": {
        "id": "Fv5nf6MCdIML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,20p' /content/End-to-end/1DCNN.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKejF5_jdNY5",
        "outputId": "abba534f-3c3b-47ec-9309-d65501eb2f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from keras.layers import Conv1D, MaxPool1D, BatchNormalization\n",
            "from keras.layers import Flatten, Dropout\n",
            "from keras import regularizers, optimizers\n",
            "from keras import backend as K\n",
            "from functools import partial as wrapped_partial\n",
            "\n",
            "from functools import partial as wrapped_partial\n",
            "\n",
            "def model_generator():\n",
            "    from keras.layers import Input, Dense\n",
            "    from keras.models import Model\n",
            "    from keras.callbacks import ModelCheckpoint\n",
            "\n",
            "    inp = Input(shape=(50999, 1))\n",
            "\n",
            "    # ----------------------\n",
            "    conv1 = Conv1D(filters=16, kernel_size=64, strides=2, activation='relu', padding='valid')(inp)\n",
            "    norm1 = BatchNormalization()(conv1)\n",
            "    pool1 = MaxPool1D(pool_size=8, strides=8)(norm1)\n",
            "    # ----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib.util\n",
        "import sys\n",
        "\n",
        "spec = importlib.util.spec_from_file_location(\n",
        "    \"cnn1d\",\n",
        "    \"/content/End-to-end/1DCNN.py\"\n",
        ")\n",
        "\n",
        "cnn1d = importlib.util.module_from_spec(spec)\n",
        "sys.modules[\"cnn1d\"] = cnn1d\n",
        "spec.loader.exec_module(cnn1d)\n"
      ],
      "metadata": {
        "id": "hzJ61r6zcDi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Resumen del modelo (Model Summary)\n",
        "\n",
        "El modelo se instancia directamente utilizando la función model_generator():"
      ],
      "metadata": {
        "id": "MJ4L-JHHD51O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn1d.model_generator()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "tfW9adjlhxPY",
        "outputId": "04118587-552b-4aca-a0c1-55f102fae54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50999\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25468\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │         \u001b[38;5;34m1,040\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25468\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3183\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1576\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m16,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1576\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m197\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m32,832\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m65,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m163,968\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50999</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25468</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25468</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3183</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1576</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1576</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m422,138\u001b[0m (1.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">422,138</span> (1.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m421,146\u001b[0m (1.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,146</span> (1.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m992\u001b[0m (3.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> (3.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La arquitectura está compuesta por:\n",
        "\n",
        "- cinco capas convolucionales 1D,\n",
        "\n",
        "- normalización por lotes (Batch Normalization),\n",
        "\n",
        "- capas de MaxPooling para reducción temporal,\n",
        "\n",
        "- capas densas finales para clasificación.\n",
        "\n",
        "El número de filtros aumenta progresivamente (16, 32, 64, 128 y 256), lo que permite al modelo capturar patrones temporales cada vez más complejos a partir de la señal de audio cruda.\n",
        "\n",
        "Este resumen del modelo permite observar claramente el número de capas y la cantidad total de parámetros, cumpliendo con el primer requisito de la actividad."
      ],
      "metadata": {
        "id": "iWyIFIycEHE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Ejemplo del tensor de entrada\n",
        "\n",
        "El modelo recibe como entrada una señal de audio crudo, sin extracción previa de características como espectrogramas o MFCCs.\n",
        "\n",
        "En este caso, la forma del tensor de entrada es: (1, 50999, 1)\n",
        "\n",
        "\n",
        "donde:\n",
        "\n",
        "- 50999 corresponde aproximadamente a 3 segundos de audio muestreado a 16 kHz,\n",
        "\n",
        "- 1 representa el canal mono de la señal.\n",
        "\n",
        "Para el análisis se genera un ejemplo sintético:"
      ],
      "metadata": {
        "id": "QukTTCu8EZes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "audio_example = np.random.uniform(\n",
        "    low=-1.0,\n",
        "    high=1.0,\n",
        "    size=(1, 50999, 1)\n",
        ")\n",
        "\n",
        "print(\"Forma del tensor:\", audio_example.shape)\n",
        "print(\"Min:\", audio_example.min())\n",
        "print(\"Max:\", audio_example.max())\n",
        "print(\"Media:\", audio_example.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjCp5xIScFa6",
        "outputId": "6ac0392f-e71a-4245-8bdc-e43d637a9e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma del tensor: (1, 50999, 1)\n",
            "Min: -0.999949919382799\n",
            "Max: 0.9999517599294587\n",
            "Media: 0.002316293469962671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los valores de entrada están normalizados en el rango\n",
        "[−1,1], lo cual representa directamente la amplitud de la onda sonora.\n",
        "Este ejemplo permite ilustrar claramente el tipo de datos que procesa la red, cumpliendo con el segundo punto de la consigna."
      ],
      "metadata": {
        "id": "e0_kRycgEfzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model.predict(audio_example)\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Forma logits:\", logits.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqA_zkb_gRRh",
        "outputId": "255a0b41-674b-4218-98cf-635e2e2939f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step\n",
            "Logits: [[ 0.00340374  0.02500429  0.14473596  0.06865323 -0.14544542  0.05130825\n",
            "  -0.0292821  -0.07832819 -0.13336335 -0.03285028]]\n",
            "Forma logits: (1, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Logits de salida del modelo\n",
        "\n",
        "La arquitectura analizada no utiliza softmax en la última capa, sino que devuelve directamente logits.\n",
        "Esto se puede observar en la definición del modelo, donde la última capa densa tiene activation=None.\n",
        "\n",
        "Los logits se obtienen directamente mediante:"
      ],
      "metadata": {
        "id": "dQTnmqQAFbyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "audio_example = np.random.uniform(-1, 1, size=(1, 50999, 1))\n",
        "logits = model.predict(audio_example)\n",
        "\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Forma:\", logits.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNGebVaZgY5x",
        "outputId": "19383919-4718-47c3-defc-37d1b732a808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Logits: [[ 0.00092261  0.00958396  0.13554879  0.06543709 -0.14621973  0.05215387\n",
            "  -0.02622733 -0.08291446 -0.12840937 -0.02563455]]\n",
            "Forma: (1, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El vector de salida tiene forma (1, 10), donde cada valor representa la evidencia no normalizada asociada a una de las 10 clases del conjunto UrbanSound8K.\n",
        "\n",
        "Posteriormente, si se desea obtener probabilidades, se puede aplicar la función softmax de manera explícita. Sin embargo, para esta práctica, el análisis se centra en los logits, ya que estos reflejan directamente la salida interna del modelo antes de la normalización."
      ],
      "metadata": {
        "id": "aBD5GpbeFjHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Carga Modelo\n",
        "Para complementar el análisis del modelo propuesto en el artículo, se consideró el uso de un modelo preentrenado para clasificación de audio ambiental denominado YAMNet. YAMNet es una red profunda preentrenada sobre el conjunto de datos AudioSet, que contiene millones de clips de audio etiquetados en más de 500 categorías acústicas, y emplea una arquitectura basada en MobileNetV1 para clasificar eventos sonoros directamente desde la señal de audio.\n",
        "\n",
        "El modelo puede descargarse y utilizarse mediante TensorFlow Hub, y se emplea frecuentemente para tareas de análisis de audio general o como extractor de características para tareas de clasificación específicas como la de sonidos ambientales.\n",
        "\n",
        "El uso de este tipo de modelos preentrenados permite aprovechar conocimiento aprendido en conjuntos de datos muy grandes y variados, lo cual puede ser útil para tareas de clasificación de audio cuando se dispone de pocos datos o se desea comparar el rendimiento con arquitecturas especializadas"
      ],
      "metadata": {
        "id": "CEmYEwsFlCep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el modelo YAMNet preentrenado desde TensorFlow Hub\n",
        "yamnet_model = hub.load(\"https://tfhub.dev/google/yamnet/1\")\n",
        "\n",
        "# Crear un ejemplo de señal de audio sintética\n",
        "# - Audio mono\n",
        "# - Muestreado a 16 kHz\n",
        "# - Valores normalizados entre -1 y 1\n",
        "# - Aproximadamente 3 segundos de duración\n",
        "waveform = np.random.uniform(\n",
        "    low=-1.0,\n",
        "    high=1.0,\n",
        "    size=(50999,)\n",
        ").astype(np.float32)\n",
        "\n",
        "# Ejecutar el modelo YAMNet sobre la señal de audio\n",
        "# scores: probabilidades por clase (521 clases de AudioSet)\n",
        "# embeddings: representaciones profundas aprendidas por la red\n",
        "# spectrogram: representación tiempo-frecuencia interna\n",
        "scores, embeddings, spectrogram = yamnet_model(waveform)\n",
        "\n",
        "# Mostrar las dimensiones de las salidas\n",
        "print(\"Dimensión de scores:\", scores.shape)\n",
        "print(\"Dimensión de embeddings:\", embeddings.shape)\n",
        "print(\"Dimensión del espectrograma:\", spectrogram.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MNhbm-GlQOM",
        "outputId": "29d1d5aa-09c9-494d-919e-80234158fb52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensión de scores: (6, 521)\n",
            "Dimensión de embeddings: (6, 1024)\n",
            "Dimensión del espectrograma: (336, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo YAMNet recibe como entrada una señal de audio mono muestreada a 16 kHz y genera como salida probabilidades por clase, embeddings de características profundas y un espectrograma interno, lo que permite analizar representaciones aprendidas a partir de grandes volúmenes de datos de audio."
      ],
      "metadata": {
        "id": "N8RhSdEimOWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Conclusiones\n",
        "\n",
        "En esta práctica se analizó una implementación entrenada real de una CNN 1D end-to-end para clasificación de sonidos ambientales.\n",
        "Se pudo observar cómo el modelo procesa directamente audio crudo, sin necesidad de transformaciones intermedias, y cómo genera logits como salida final.\n",
        "\n",
        "El uso del repositorio oficial permitió trabajar con una arquitectura fiel a la propuesta original del artículo. Además, el análisis del resumen del modelo, del tensor de entrada y de los logits de salida permitió comprender mejor el funcionamiento interno de la red.\n",
        "\n",
        "Este enfoque demuestra que es posible realizar clasificación de sonidos ambientales de manera eficiente utilizando redes convolucionales 1D entrenadas de extremo a extremo."
      ],
      "metadata": {
        "id": "BsyLNjdWFrPN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZb092svjAgN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}